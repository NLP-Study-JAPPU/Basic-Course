
## Paper List
- #### 00 : OT
  > [Presentation](https://github.com/NLP-Study-JAPPU/Basic-Course/blob/main/Presentations/OT.pdf) 
  > 
  > - Date : 2024.01.02 
  > - Presentor : 유하영

- #### 01 : Efficient Estimation of Word Representations in Vector Space
  > [Paper](https://arxiv.org/pdf/1301.3781.pdf), [Presentation](https://github.com/NLP-Study-JAPPU/Basic-Course/blob/main/Presentations/Word2Vec_24.01.11_%E1%84%92%E1%85%AA%E1%86%BC%E1%84%92%E1%85%A7%E1%86%AB%E1%84%90%E1%85%A2.pdf), [CBOW](https://github.com/NLP-Study-JAPPU/Basic-Course/blob/main/Code/Word2Vec/Word2Vec(CBOW).py), [Skip-gram](https://github.com/NLP-Study-JAPPU/Basic-Course/blob/main/Code/Word2Vec/Word2Vec(Skip_gram).py)</br>
  > Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean.
  >
  > - Keywords : `Word2vec`
  > - Date : 2024.01.11
  > - Presentor : 황현태
  > - [Paper Review](https://oneul-hyeon.tistory.com/518)
  > - [Code Review(CBOW)](https://oneul-hyeon.tistory.com/530)
  > - [Code Review(Skip-gram)](https://oneul-hyeon.tistory.com/531)

- #### 02 : Distributed Representations of Words and Phrases and their Compositionality
  > [Paper](https://nlp.stanford.edu/pubs/glove.pdf), Presentation</br> 
  > Pennington, Jeffrey, Richard Socher, and Christopher D. Manning. 2014.
  >
  > - Keywords : `GloVe`
  > - Date : 2024.01.11
  > - Presentor : 유하영

- #### 03 : Enriching Word Vectors with Subword Information
  > [Paper](https://aclanthology.org/Q17-1010.pdf), [Presentation](https://ownogatari.xyz/posts/fasttext/)</br> 
  > P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov, “Enriching Word Vectors with Subword Information,” Transactions of the Association for Computational Linguistics, vol. 5, pp. 135–146, 2017
  >   
  > - Keywords : `FastText`
  > - Date : 2024.01.11
  > - Presentor : 오원준
  
- #### 04 : Sequence to Sequence Learning with Neural Networks
  > [Paper](https://proceedings.neurips.cc/paper_files/paper/2014/file/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf), [Presentation](https://github.com/NLP-Study-JAPPU/Basic-Course/blob/main/Presentations/seq2seq_24.01.18_%EC%9C%A0%ED%95%98%EC%98%81.pdf)</br> 
  > Pennington, Jeffrey, Richard Socher, and Christopher D. Manning. 2014.
  >
  > - Keywords : `seq2seq`
  > - Date : 2024.01.18
  > - Presentor : 유하영

- #### 05 : Convolutional Neural Networks for Sentence Classification.
  > [Paper](https://aclanthology.org/D14-1181.pdf), [Presentation](https://ownogatari.xyz/posts/textcnn/)</br> 
  > Yoon Kim. 2014. Convolutional Neural Networks for Sentence Classification. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1746–1751, Doha, Qatar. Association for Computational Linguistics.
  >   
  > - Keywords : `TextCNN`
  > - Date : 2024.01.18
  > - Presentor : 오원준
  >

- #### 06 : NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE
  > [Paper](https://arxiv.org/pdf/1409.0473.pdf), [Presentation](https://github.com/NLP-Study-JAPPU/Basic-Course/blob/main/Presentations/Seq2Seq_24.03.03_%E1%84%92%E1%85%AA%E1%86%BC%E1%84%92%E1%85%A7%E1%86%AB%E1%84%90%E1%85%A2.pdf), [Code](https://github.com/NLP-Study-JAPPU/Basic-Course/blob/main/Code/Seq2Seq/Seq2Seq%20with%20Attention.py)</br> 
  > Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. "Neural machine translation by jointly learning to align and translate." arXiv preprint arXiv:1409.0473 (2014). 
  > - Keywords : `Attention`
  > - Date : 2024.02.25
  > - Presentor : 황현태
  >

- #### 07 : NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE
  > [Paper](https://arxiv.org/pdf/1409.0473.pdf), [Presentation](https://github.com/NLP-Study-JAPPU/Basic-Course/blob/main/Presentations/Attention_24.03.03_%EC%9C%A0%ED%95%98%EC%98%81.pdf)</br> 
  > Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. "Neural machine translation by jointly learning to align and translate." arXiv preprint arXiv:1409.0473 (2014). 
  > - Keywords : `Attention`
  > - Date : 2024.03.03
  > - Presentor : 유하영

- #### 08 : A Fast and Accurate Dependency Parser using Neural Networks
  > [Paper](https://emnlp2014.org/papers/pdf/EMNLP2014082.pdf), [Presentation](https://github.com/NLP-Study-JAPPU/Basic-Course/blob/main/Presentations/AFastandAccurateDependencyParserusingNeuralNetworks_%EC%B1%84%EC%A3%BC%EC%99%84.pdf)</br> 
  > Chen, Danqi  and Manning, Christopher. "A Fast and Accurate Dependency Parser using Neural Networks" Association for Computational Linguistics 740–750(2014).
  > - Keywords : `Word Embedding`, `Dependency Parsing`
  > - Date : 2024.03.24
  > - Presentor : 채주완

- #### 09 : BLEU: A METHOD FOR AUTOMATIC EVALUATION OF MACHINE TRANSLATION
  > [Paper](https://aclanthology.org/P02-1040.pdf), [Presentation](https://github.com/NLP-Study-JAPPU/Basic-Course/blob/main/Presentations/bleuscore_%EC%B1%84%EC%A3%BC%EC%99%84.pdf)</br> 
  > Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. "BLEU: a Method for Automatic Evaluation of Machine Translation" Computational Linguistics (ACL), Philadelphia, July 2002, pp. 311-318.
  > - Keywords : `Machine Translation`, `MT Evaluation`, `BLEU score`
  > - Date : 2024.03.31
  > - Presentor : 채주완

- #### 10 : Attention Is All You Need
  > [Paper](https://arxiv.org/pdf/1706.03762.pdf), [Presentation](https://github.com/NLP-Study-JAPPU/Basic-Course/blob/main/Presentations/Transformer_%EB%82%98%EB%B3%B4%EC%98%81.pdf)</br> 
  > VASWANI, Ashish, et al. Attention is all you need. Advances in neural information processing systems, 2017, 30.
  > - Keywords : `Transformer`
  > - Date : 2024.03.31, 2024.04.07
  > - Presentor : 나보영

- #### 11 : Attention Is All You Need
  > [Paper](https://arxiv.org/pdf/1706.03762.pdf), [Presentation](https://github.com/NLP-Study-JAPPU/Basic-Course/blob/main/Presentations/Attention%EC%84%B8%EB%B6%80.pdf)</br> 
  > VASWANI, Ashish, et al. Attention is all you need. Advances in neural information processing systems, 2017, 30.
  > - Keywords : `Transformer`
  > - Date : 2024.04.07
  > - Presentor : 채주완

- #### 12 : BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
  > [Paper](https://arxiv.org/pdf/1810.04805.pdf#page=11&zoom=100,402,182), [Presentation](https://github.com/NLP-Study-JAPPU/Basic-Course/blob/main/Presentations/bert.pdf)</br> 
  > Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.
  > - Keywords : `Pre-training`, `Transformer`
  > - Date : 2024.04.14
  > - Presentor : 채주완

- #### 13 : 양방향 LSTM 기반 한국어 음성 비속어
  > [Paper](https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11699989&language=ko_KR&hasTopBanner=true), [Presentation](https://github.com/NLP-Study-JAPPU/Basic-Course/blob/7f3e6c32711abd418428c80d2fc1ca0d4edd3357/Presentations/%EC%96%91%EB%B0%A9%ED%96%A5-LSTM-%EA%B8%B0%EB%B0%98--%ED%95%9C%EA%B5%AD%EC%96%B4-%EC%9D%8C%EC%84%B1-%EB%B9%84%EC%86%8D%EC%96%B4-%ED%95%84%ED%84%B0%EB%A7%81_%EB%82%98%EB%B3%B4%EC%98%81.pdf)</br> 
  > 김혜영, 이영우, 서지헌, 박성민, 김현우, 박영진. (2024). 양방향 LSTM 기반 한국어 음성 비속어 필터링. 멀티미디어학회논문지, 27(1), 126-133, 10.9717/kmms.2024.27.1.126
  > - Keywords : `Online Language Violence` , `Deep Learning`, `Speech-to-Text`, `Bidirectional LSTM`
  > - Date : 2024.04.14
  > - Presentor : 나보영

- #### 14 : Improving Language Understanding by Generative Pre-Training
  > [Paper](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf), [Presentation]()</br> 
  > Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever. (2018). Radford, Alec and Karthik Narasimhan. “Improving Language Understanding by Generative Pre-Training.” (2018).
  > - Keywords : `Generative Pre-Training` , `Language Models`, `Natural Language Understanding`
  > - Date : 2024.04.28
  > - Presentor : 채주완

- #### 15 : Attention Is All You Need
  > [Paper](https://arxiv.org/pdf/1706.03762.pdf), [Presentation]()</br> 
  > VASWANI, Ashish, et al. Attention is all you need. Advances in neural information processing systems, 2017, 30.
  > - Keywords : `Transformer`
  > - Date : 2024.05.05, 2024.05.19
  > - Presentor : 유하영

- #### 16 : ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators
  > [Paper](https://openreview.net/pdf?id=r1xMH1BtvB), [Presentation](https://github.com/NLP-Study-JAPPU/Basic-Course/blob/main/Presentations/ELECTRA_%EC%A1%B0%ED%83%9C%EC%99%84.pdf)</br> 
  > Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning. (2020). Clark, Kevin, Minh-Thang Luong, Quoc V. Le, and Christopher D. Manning. “ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators.” (2020).
  > - Keywords : `ELECTRA`, `BERT`, `Transformer`
  > - Date : 2024.05.05
  > - Presentor : 조태완

- #### 17 : Mamba: Linear-Time Sequence Modeling with Selective State Spaces
  > [Paper](https://arxiv.org/abs/2312.00752), [Presentation](https://github.com/NLP-Study-JAPPU/Basic-Course/blob/main/Presentations/Sequence_Modeling_with_State_Space_Models_%E1%84%90%E1%85%A2%E1%84%8B%E1%85%AA%E1%86%AB.pdf)</br> 
  > Albert Gu, Tri Dao. (2023). Gu, Albert and Dao, Tri. “Mamba: Linear-Time Sequence Modeling with Selective State Spaces.” (2023).
  > - Keywords : `Linear-Time Sequence Modeling`, `Selective State Spaces`, `HiPPO`, `S3`, `S4`, `S4`, `Mamba`,   
  > - Date : 2024.05.26
  > - Presentor : 조태완
